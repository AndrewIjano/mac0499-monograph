%!TeX root=../tese.tex

\chapter{Development}
\label{cap:development}

In this section, we describe the development of a tractable algorithm for PGEL-SAT\footnote{Available at \url{https://github.com/AndrewIjano/pgel-sat}.}, described by \citet{Fin2020}. It was implemented using Python programming language \citep{python3}. \todo{Numpy}

\section{Input and output format}

The algorithm accepts as input a $\pgel$ KB encoded in an OWL 2 ontology. Both certain and uncertain knowledge must be a $\gel$-CBox in the normal form, with the additional support of equivalence axioms. Due to limitations in the OWL parser used, which will be detailed further, RDF/XML, OWL/XML and NTriples are the only file formats supported.

In addition, uncertain axioms must have an annotation (\texttt{rdfs:comment}) with its unique numerical index. That is, given an uncertain axiom $Ax_i$, its annotation must be of the following form in \autoref{fig:annot-axiom}.
\begin{figure}
	\centering
	\begin{minipage}{6cm}
		\begin{lstlisting}[style=mystyle]
      #!pbox-id $i$
    \end{lstlisting}
	\end{minipage}
	\caption{Annotation format for an uncertain axiom}
	\label{fig:annot-axiom}
\end{figure}

PBox restrictions are represented with annotations in the $\top$ concept (\texttt{owl:Thing}). That is, given a restriction of the form $a_0 P(Ax_0) + a_1P(Ax_1) + \cdots + a_{n-1} P(Ax_{n-1}) = b$, its annotation must be of the form in \autoref{fig:pbox-rest}.  Also, inequalities $\leq$ and $\geq$ can be represented, respectively, with the symbols \texttt{<=} and \texttt{>=}.

\begin{figure}
	\centering
	\begin{minipage}{6cm}
		\begin{lstlisting}[style=mystyle]
    #!pbox-restriction
    0   $a_0$
    1   $a_1$
    $\cdots$
    $n-1$ $a_{n-1}$
    ==
    $b$
    \end{lstlisting}
	\end{minipage}
	\caption{Annotation format for a PBox restriction}
	\label{fig:pbox-rest}
\end{figure}


The output of the algorithm is \texttt{True} if the given KB has a solution, and \texttt{False} if not.

\improvement{Maybe explain how to execute the algorithm}

\section{Knowledge base representation}
To read the ontology in OWL 2, it was used the Python module \textit{Owlready2} \citep{lamy2017owlready}.


The probabilistic KB is represented as the edge-labeled graph in \autoref{subsec:graph-repr} with three matrices for the inequalities in \autoref{eq:pbox-restric}.

\improvement[inline]{Need to improve this}

The probabilistic KB representation allows us to develop a PGEL-SAT solver, using this data structure as input.

\section{PGEL-SAT solver}
\label{sec:pgelsatsolver}

In order to understand the PGEL-SAT solver implemented, we need to find a solution for the linear system stated in \autoref{subsec:lin-alg-view}.

First, consider the matrix $C$ in \autoref{eq:pbox-restric}, it has $p$-columns and $\pi$-columns, referring to which part of $x$ they multiply. We say that a $p$-column $pc_i$ is \emph{well-formed} if it is of the form in \autoref{eq:pbox-restric}, starting with the $i$-th column of $-I_n$, followed by the $i$-th column of $A$ and with one $0$ at the end. Also, we say that a $\pi$-column is \emph{well-formed} if it starts with a corresponding vector of an interpretation model of $\CC$, followed by $k$ zeros and with one $1$ at the end. A column that is not well-formed is \emph{ill-formed}.

Now, consider that the matrix $C$ may have ill-formed columns. We define a binary \emph{cost vector} $c$ such that each element $c_i = 1$ iff column $C^i$ is ill-formed; otherwise $c_i = 0$. Then, the linear system stated in \autoref{subsec:lin-alg-view} has a solution iff the following minimization problem has minimum 0.

\begin{equation}
	\label{eq:linprog}
	\begin{array}{ll}
		\text{minimize}   & c' \cdot x    \\
		\text{subject to} & C \cdot x = d \\
		                  & x \geq 0
	\end{array}
\end{equation}

This problem can be solved by a linear algebraic solver but we need to find beforehand $C$ and $d$ that reaches the minimum 0. Since matrix $A$ and vector $b$ are generated from PBox, we need to choose a set of interpretations that provides the solution. However, we potentially have an exponential collection of possible interpretations, and looking over all of them would make the algorithm untractable. \todo{Need to say about M being large not the collection of possible columns}

Even though, from CarathÃ©odory's Theorem \citep{eckhoff1993helly}, \citet{Fin2020} states that if constrains in \autoref{eq:pbox-restric} are solvable then there exists  a solution where $x$ has at most $n + k + 1$ values such that $x_j > 0$. This allows us to avoid generating an exponential number of columns of $C$ by using a linear algebraic technique called \emph{column generation} \citep{gilmore1961linear,gilmore1963linear}. With this technique, we can create an algorithm \textsc{PGEL-SAT-Solver} which generates well-formed $\pi$-columns of $C$ on the fly by solving an auxiliary problem and uses a linear solver in each iteration to verify if the solution for \autoref{eq:linprog} has reached minimum 0. This solution leads to the algorithm implemented, which is shown in \autoref{alg:pgelsat}.

\begin{algorithm}
	\caption{The PGEL-SAT solver algorithm}
	\label{alg:pgelsat}
	\begin{algorithmic}[1]
		\Function {PGEL-SAT-Solver}{$\tuple{\CC, \PP}$}
		\State $c \gets \Call{Initialize-c}{\PP}$
		\State $C \gets \Call{Initialize-C}{\PP}$
		\State $d \gets \Call{Initialize-d}{\PP}$
		\Statex
		\State $lp \gets \Call{LinProg}{c, C, d}$
		\Statex
		\While{$lp.minCost \neq 0$}
		\State $result \gets \Call{GenerateColumn}{\tuple{\CC, \PP}, lp}$
		\If{$result.isSuccess = \text{False}$}
		\State \textbf{return} False \Comment{$\tuple{\CC, \PP}$ is unsatisfiable}
		\EndIf
		\Statex
		\State $y \gets result.column$ \Comment{well-formed $\pi$-column}
		\State $C \gets ( C \, | \, y) $
		\State $c \gets (c \, | \, 0)$
		\State $lp \gets \Call{LinProg}{c, C, d}$
		\EndWhile
		\Statex
		\State \textbf{return} $($True$, lp)$ \Comment{$\tuple{\CC, \PP}$ is satisfiable}
		\EndFunction
	\end{algorithmic}
\end{algorithm}

\begin{algorithm}
	\caption{Matrices initializations}
	\label{alg:mat-init}
	\begin{algorithmic}[1]
		\Function {Initialize-c}{$\PP$}
		\State \textbf{return} $(\, 1'_{n + k + 1} \, | \, 0'_n \,)'$
		\EndFunction
		\Statex
		\Function {Initialize-C}{$\PP$}
		\State Get $A$ from PBox $\PP$ restrictions
		\State $\vphantom{\begin{smallmatrix}\vphantom{x}\\-I_n\\A\\1'_n\\\vphantom{x}\end{smallmatrix}}$
		$PC$ $\gets \left( \begin{smallmatrix}
					-I_n\\
					A\\
					1'_n\\
				\end{smallmatrix} \right)$  \Comment{$p$-columns}
		\State \textbf{return} $(\, I_{n + k + 1} \, | \, PC \,)$
		\EndFunction
		\Statex
		\Function {Initialize-d}{$\PP$}
		\State Get $b$ from PBox $\PP$ restrictions
		\State \textbf{return} $(\, 0'_n \, | \, b' \, | \, 1 \,)'$
		\EndFunction
	\end{algorithmic}
\end{algorithm}

The algorithm \textsc{PGEL-SAT-Solver} in \autoref{alg:pgelsat} receives a potentially unsatisfiable probabilistic knowledge base and returns \emph{True} if it is satisfiable, and \emph{False}, otherwise.

It starts with matrices $c$,  $C$ and $d$. Because the algorithm needs to start with a cost vector with non-zero elements, the $C$ matrix is initialized with $n + k + 1$ ill-formed columns, represented by the identity matrix $I_{n + k + 1}$, and well-formed $p$-columns as shown in \autoref{eq:pbox-linear}; therefore, the cost vector $c$ is initialized with $n + k + 1$ $1$-elements plus $n$ $0$-elements. The $d$ vector is unaltered during the execution and is given by \autoref{eq:pbox-linear}. These initializations are shown in \autoref{alg:mat-init}.

In addition, the algorithm uses a program \textsc{LinProg}. It receives matrices $c$, $C$ and $d$ and returns the solution for the optimization problem in \autoref{eq:linprog}. Its output $lp$ needs to contain the minimal cost ($lp.minCost$), the primal solution ($lp.primal$) and dual solution ($lp.dual$).

Then, the algorithm executes the column generation process while the minimal cost is not zero. In each iteration, a well-formed $\pi$-column $y$ is generated by an auxiliary program \textsc{GenerateColumn}. After that, the column is appended to $C$, with its respective $0$ cost in $c$, and a new minimal cost is calculated. If no more columns can be generated with a minimal cost higher than $0$, represented by $result.isSuccess = False$, the KB is unsatisfiable.

\section{Linear solver}
The program \textsc{LinProg} was implemented using the open-source GNU linear program kit \citep{makhorin2001gnu} and the Python wrapper for this library, the \emph{swiglpk} package \citep{swiglpk}. The library was chosen because it is open-source, has tractable algorithms for large-scale problems, and provides a solution that contains the required elements described in \autoref{sec:pgelsatsolver}.

There are several methods for solving a linear optimization problem. The \emph{simplex method} is known to be very efficient in practice \citep{borgwardt2012simplex} although its worst time complexity is untractable \citep{klee1972good}. On the other hand, the modern \emph{interior point method} has a proven polynomial-time complexity and is especially ideal for very sparse problems \citep{boyd2004convex} but may not be as efficient as the simplex method in all cases.

Because of the theoretical tractability, the linear solver \textsc{LinProg} implemented uses the interior point method.

\section{Column generation}
The program \textsc{GenerateColumn} is responsible for generating a well-formed $\pi$-column for $C$ that reduces $c' x$ until it is minimal; in particular, when the KB is satisfiable, this value is equal to 0. To find such a column, we need to analyze the optimization problem we are solving from the theory of linear programming \citep{bertsimas1997introduction}.

\subsection{Cost reduction}

Suppose that the matrix $C$ is composed of $I_{n+k+1}$ and all well-formed $p$-columns $PC$, which are result of \textsc{Initialize-C}, concatenated with all possible (ill and well formed) $\pi$-columns $y^{(j)}$, as illustrated below.

\[
	C := \left( I_{n+k+1} \, | \, PC \, | \, y^{(1)} \, | \, y^{(2)} \, \cdots \, \right)
\]

This matrix can be rearranged in the form $C = (B \, | \, N)$, where $B$ is a linear independent square matrix called \emph{basis matrix}. This allows obtaining a \emph{basic feasible solution} $x = (\, x_B' \, | \, x_N' \,)'$ where $x_N = 0$ and $x_B = B^{-1}d$. In particular, if $B = I_{n+k+1}$ we have $x_B = d$.


However, this solution may, and probably will, not be optimal. Then, we need to find some column $C^j$ in $N$ and increase $x_j$ by some positive value $\theta$, moving $x$ to $x + \theta s$, for some $s$. We create this vector~$s$ such that $s_j = 1$, $s_i = 0$ for every non basic index $i \neq j$ and its basic part $s_B = (s_{B(1)}, s_{B(2)}, \dots, s_{B(m)})$.

Since we want feasible solution, we need $C (x + \theta s) = d$; given that $x$ is feasible, we also have $C x = d$. Thus, we need $C \cdot s = C \cdot (x + \theta s - x) = d - d = 0$. Also, because $s_j = 1$ and $s_i = 0$ for every non basic index $i \neq j$, we have that
\[
	0 = C s = \sum_{i = 1}^{n + k + 1} C_i s_i = \sum_{i = i}^m C_{B(i)} s_{B(i)} + C_j = B s_B + C_j.
\]

This follows that $s_B = - B^{-1} C_j$.

Then, we could calculate the variation of the objective function by:
\begin{align*}
	c' (x + \theta s) - c'x & = \theta c's = \theta (c_j + c_B' s_B) = \theta (c_j - c'_B B^{-1} C_j).
\end{align*}
This value $r_j := c_j - c'_B B^{-1} C_j$ is called \emph{reduced cost} of the variable $x_j$. The quantity is useful for finding columns in $C$ that lead to an optimal solution. In case of nondegeneracy, if $r_j < 0$ for some $j$, we could minimize the goal increasing $x_j$.

\improvement[inline]{Explain the derivation of reduced cost}

From that, we define that the \emph{reduced cost} $r_y$ of a column $y$ to be added to the solution is
\[
	r_y = c_y - w \cdot y.
\]

Because $y$ is well-formed, we have $c_y = 0$. Then, to reduce the cost of the objective function, we need $r_y \leq 0$ and, therefore, the new column must satisfy
\begin{equation}
	\label{eq:col-restr}
	w \cdot y \geq 0.
\end{equation}

\subsection{Intermediate problem}

In this algorithm, only the $n$ first elements, which correspond to a column of $M$, must be generated, since the last elements are composed of $k$ 0-elements and one 1-element. This new column $M^j$ is the corresponding vector in $\PP$ of a $C$-satisfiable interpretation. Then, to find such column, we can solve an intermediate problem.

Define $\CC \cup \PP$ as a potentially unsatisfiable CBox with all axioms of $\CC$ and axioms from restrictions of $\PP$. We want to find a new CBox $\CC^\bullet \subseteq \CC \cup \PP$ such that $\CC^\bullet$ is satisfiable and $\CC^\bullet \models C \isa D$ if $C \isa D \in \CC$. An interpretation model of $\CC^\bullet$ will be $\CC$-satisfiable and can generate a corresponding vector $M^j$ in $\PP$. Also, the new column $y$ created from $M^j$ must obey the restriction in \autoref{eq:col-restr}.

Instead of generating a column $y$ that just satisfies the conditions above, we could generate one that maximizes the cost reduction in \autoref{eq:col-restr}. This can be done maximizing $\sum_{i = 1}^n w_i \cdot y_i$ which is choosing axioms $Ax_i$ for $\CC^\bullet$ based on weights $w_i$, $1 \leq i \leq n$.

Then, this problem can be modeled as a $\gel$-MaxSAT for $\CC \cup \PP$ where axioms of $\CC$ have infinite weight and every axiom $Ax_i$ from $\PP$ has weight $w_i$. 

\subsection{Generating column}

This leads to the solution in \autoref{alg:gen-col}. We generate a new column solving the intermediate problem with $\gel$\textsc{-Max-SAT-Solver} and an auxiliary function \textsc{ExtractColumn}. If the $\gel$-MaxSAT problem does not have a solution or \autoref{eq:col-restr} cannot be satisfied, it returns False; otherwise, it returns True and the generated column $y$. 

\begin{algorithm}
	\caption{The algorithm of column generation}
	\label{alg:gen-col}
	\begin{algorithmic}[1]
		\Function {GenerateColumn}{$\tuple{\CC, \PP}, lp$}
		\State $w \gets lp.dual$
		\State $result \gets \Call{$\gel$-Max-SAT-Solver}{\CC \cup \PP, (w_1, \dots, w_n)}$
		\If{$result.isSuccess = \text{False}$}
		\State \textbf{return} False
		\EndIf
		\Statex
		\State $y \gets \Call{ExtractColumn}{result}$
		\If{$w \cdot y < 0$}
		\State \textbf{return} False
		\EndIf
		\Statex
		\State \textbf{return} $($True$, y)$
		\EndFunction
		\Statex
		\Function{ExtractColumn}{$result$}
		\State $\CC_{max} \gets result.solution$
		\State Define $n$-vector $m_n$ such that $m_i = 1$ iff we have $Ax_i$ in $\CC_{max}$
		\State $y \gets (\, m_n' \, | \, 0_k' \, |\, 1 \,)'$
		\State \textbf{return} $y$
		\EndFunction
	\end{algorithmic}
\end{algorithm}


\section{\texorpdfstring{$\gel$}{GEL}-MaxSAT solver}

The function $\gel$\textsc{-Max-SAT-Solver} is responsible for generating a solution to the $\gel$-MaxSAT problem. To find such solution, we need to look at the graph modeling used for its SAT decision.

A weighted $\gel$-CBox $\tuple{\CC\cup\PP, w}$ can be represented as a weighted directed graph $G_w(\CC\cup\PP) = (N, E, \ell, w)$, following the representation in \autoref{sec:gel}, where $(N, E, \ell)$ are the same as before and $w: E \to \Ratios \cup \{\infty\}$ is an edge weight function with $w\left(\left(C \to_0 D\right)\right) = \infty$ iff $C \isa D \in \CC$.

In this problem, we want to find a satisfiable subset of $\CC \cup \PP$. From \autoref{theorem:gel-sat}, we know that a $\gel$-CBox $\CC$ is satisfiable iff there is a $Init$-$\bot$ path in $G(\CC)$. Thus, to find a satisfiable $\CC^\bullet \subseteq \CC \cup \PP$, we need to remove every $Init$-$\bot$ path in $G_w(\CC \cup \PP)$ which can be done by removing some edges in these paths. For maximality, we need to remove edges that minimize the sum of weights of the deleted set.

Also, given a weighted directed graph $G_w(\CC)$ and nodes $s, t \in N$, a $s$-$t$ \emph{cut} in $G_w(\CC)$ is a partition $(S, T)$ such that $s \in S$ and $t \in T$. A \emph{cut set} $Cut(S, T)$ is the set of edges of $G_w(\CC)$ with one end in $S$ and other end in $T$; we use $Cut(s, t)$ to refer to a cut set from a $s$-$t$ cut.  To remove all paths from $s$ to $t$, we need to remove all edges of a cut set $Cut(s, t)$. The weight of a cut set is given by the sum of weights of its edges:
\[
	w(Cut(s, t)) = \sum_{(u, v) \, \in \, Cut(s, t)} w(u, v).	
\]
A graph usually has many $s$-$t$ cuts; a $s$-$t$ cut is \emph{minimal} (\emph{min cut}) if it has minimal weight; it is finite if its cut set has only edges of finite weight.

explain mincut and max sat

explain algorithm

explain weights

explain weight infinite

\begin{algorithm}
	\caption{The $\gel$-MaxSAT solver algorithm}
	\label{alg:max-sat}
	\begin{algorithmic}[1]
		\Function {$\gel$-Max-SAT-Solver}{$\CC \cup \PP, w$}
		\State Compute $G_w(\CC \cup \PP) \gets (N, E, \ell, w)$
		\State $Cut(Init, \bot) \gets \Call{MinCut}{G_w(\CC \cup \PP),\, Init,\, \bot}$
		\If{$w(Cut(Init, \bot)) = \infty$}
		\State \textbf{return} False
		\EndIf
		\Statex
		\State \textbf{return} $($True$, CS.indexes)$
		\EndFunction
	\end{algorithmic}
\end{algorithm}


\begin{algorithm}
	\caption{The minimal cut algorithm}
	\label{alg:max-sat}
	\begin{algorithmic}[1]
		\Function {MinCut}{$G_w(\CC \cup \PP),\, Init,\, \bot$}
		\EndFunction
	\end{algorithmic}
\end{algorithm}

\section{Time complexity analysis}

